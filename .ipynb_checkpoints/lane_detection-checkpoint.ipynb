{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANE DETECTION\n",
    "> Lane coloration has become popular in real time vehicular ad-hoc networks (VANETs). The main emphasis of this paper is to find the further ways which can be used further to improve the result of lane detection algorithms. Noise, visibility etc. can reduce the performance or the existing lane detection algorithms. The methods developed so far are working efficiently and giving good results in case when noise is not present in the images. But problem is that they fail or not give efficient results when there is any kind of noise or fog in the road images. The noise can be anything like dust, shadows, puddles, oil stains, tire skid marks, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane detection on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n",
      "(540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    #channel_count = img.shape[2]\n",
    "    match_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def drow_the_lines(img, lines):\n",
    "    img = np.copy(img)\n",
    "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(blank_image, (x1,y1), (x2,y2), (0, 255, 0), thickness=10)\n",
    "\n",
    "    img = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "    return img\n",
    "\n",
    "def process(image):\n",
    "    print(image.shape)\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    region_of_interest_vertices = [\n",
    "        (0, height),\n",
    "        (width/2, height/2),\n",
    "        (width, height)\n",
    "    ]\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    canny_image = cv2.Canny(gray_image, 100, 120)\n",
    "    cropped_image = region_of_interest(canny_image,\n",
    "                    np.array([region_of_interest_vertices], np.int32),)\n",
    "    lines = cv2.HoughLinesP(cropped_image,\n",
    "                            rho=2,\n",
    "                            theta=np.pi/180,\n",
    "                            threshold=50,\n",
    "                            lines=np.array([]),\n",
    "                            minLineLength=40,\n",
    "                            maxLineGap=100)\n",
    "    image_with_lines = drow_the_lines(image, lines)\n",
    "    return image_with_lines\n",
    "\n",
    "cap = cv2.VideoCapture('solidWhiteRight.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = process(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
